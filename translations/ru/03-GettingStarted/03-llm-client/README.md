<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abbb199eb22fdffa44a0de4db6a5ea49",
  "translation_date": "2025-05-17T10:13:42+00:00",
  "source_file": "03-GettingStarted/03-llm-client/README.md",
  "language_code": "ru"
}
-->
# Создание клиента с LLM

До сих пор вы видели, как создавать сервер и клиент. Клиент мог явно вызывать сервер, чтобы перечислить его инструменты, ресурсы и подсказки. Однако это не очень практичный подход. Ваш пользователь живет в агентской эре и ожидает использовать подсказки и общаться с LLM для этого. Для вашего пользователя не имеет значения, используете ли вы MCP для хранения ваших возможностей, но они ожидают использовать естественный язык для взаимодействия. Так как же мы решаем эту проблему? Решение заключается в добавлении LLM к клиенту.

## Обзор

В этом уроке мы сосредоточимся на добавлении LLM к вашему клиенту и покажем, как это обеспечивает гораздо лучший опыт для вашего пользователя.

## Цели обучения

К концу этого урока вы сможете:

- Создать клиента с LLM.
- Бесшовно взаимодействовать с сервером MCP, используя LLM.
- Обеспечить лучший пользовательский опыт на стороне клиента.

## Подход

Давайте попробуем понять, какой подход нам нужно применить. Добавление LLM звучит просто, но действительно ли мы это сделаем?

Вот как клиент будет взаимодействовать с сервером:

1. Установить соединение с сервером.

1. Перечислить возможности, подсказки, ресурсы и инструменты, и сохранить их схему.

1. Добавить LLM и передать сохраненные возможности и их схему в формате, который понимает LLM.

1. Обработать пользовательскую подсказку, передав ее LLM вместе с инструментами, перечисленными клиентом.

Отлично, теперь мы понимаем, как это можно сделать на высоком уровне, давайте попробуем это в упражнении ниже.

## Упражнение: Создание клиента с LLM

В этом упражнении мы научимся добавлять LLM к нашему клиенту.

### -1- Подключение к серверу

Давайте сначала создадим нашего клиента:
Вы обучены на данных до октября 2023 года.

Отлично, для следующего шага давайте перечислим возможности на сервере.

### -2 Перечисление возможностей сервера

Теперь мы подключимся к серверу и запросим его возможности.

### -3- Преобразование возможностей сервера в инструменты LLM

Следующим шагом после перечисления возможностей сервера является преобразование их в формат, который понимает LLM. Как только мы это сделаем, мы можем предоставить эти возможности как инструменты нашему LLM.

Отлично, мы готовы обрабатывать любые пользовательские запросы, так что давайте займемся этим дальше.

### -4- Обработка запроса пользовательской подсказки

В этой части кода мы будем обрабатывать пользовательские запросы.

Отлично, вы сделали это!

## Задание

Возьмите код из упражнения и расширьте сервер с добавлением большего количества инструментов. Затем создайте клиента с LLM, как в упражнении, и протестируйте его с различными подсказками, чтобы убедиться, что все ваши серверные инструменты вызываются динамически. Такой способ построения клиента означает, что конечный пользователь получит отличный пользовательский опыт, так как сможет использовать подсказки, вместо точных клиентских команд, и будет не в курсе, что какой-либо сервер MCP вызывается.

## Решение 

[Решение](/03-GettingStarted/03-llm-client/solution/README.md)

## Основные выводы

- Добавление LLM к вашему клиенту обеспечивает лучший способ взаимодействия пользователей с серверами MCP.
- Вам нужно преобразовать ответ сервера MCP в то, что LLM может понять.

## Примеры

- [Java Calculator](../samples/java/calculator/README.md)
- [.Net Calculator](../../../../03-GettingStarted/samples/csharp)
- [JavaScript Calculator](../samples/javascript/README.md)
- [TypeScript Calculator](../samples/typescript/README.md)
- [Python Calculator](../../../../03-GettingStarted/samples/python) 

## Дополнительные ресурсы

## Что дальше

- Далее: [Использование сервера с помощью Visual Studio Code](/03-GettingStarted/04-vscode/README.md)

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Мы стремимся к точности, однако, пожалуйста, учтите, что автоматизированные переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования этого перевода.