<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "25a94c681cf43612ff394d8cf78a74de",
  "translation_date": "2025-05-27T16:06:03+00:00",
  "source_file": "00-Introduction/README.md",
  "language_code": "da"
}
-->
# Introduktion til Model Context Protocol (MCP): Hvorfor det er vigtigt for skalerbare AI-applikationer

Generative AI-applikationer er et stort fremskridt, da de ofte lader brugeren interagere med appen via naturlige sprogkommandoer. Men efterh√•nden som der investeres mere tid og ressourcer i s√•danne apps, vil du sikre, at du nemt kan integrere funktionaliteter og ressourcer p√• en m√•de, der g√∏r det let at udvide, at din app kan h√•ndtere mere end √©n model, og at den kan h√•ndtere forskellige modelkompleksiteter. Kort sagt er det nemt at komme i gang med at bygge Gen AI-apps, men efterh√•nden som de vokser og bliver mere komplekse, skal du begynde at definere en arkitektur og sandsynligvis bruge en standard for at sikre, at dine apps bliver bygget p√• en ensartet m√•de. Det er her MCP kommer ind og organiserer tingene og leverer en standard.

---

## **üîç Hvad er Model Context Protocol (MCP)?**

**Model Context Protocol (MCP)** er et **√•bent, standardiseret interface**, der g√∏r det muligt for store sprogmodeller (LLMs) at interagere gnidningsfrit med eksterne v√¶rkt√∏jer, API‚Äôer og datakilder. Det giver en ensartet arkitektur, der forbedrer AI-modellers funktionalitet ud over deres tr√¶ningsdata, hvilket muligg√∏r smartere, skalerbare og mere responsive AI-systemer.

---

## **üéØ Hvorfor standardisering inden for AI er vigtigt**

Efterh√•nden som generative AI-applikationer bliver mere komplekse, er det afg√∏rende at anvende standarder, der sikrer **skalerbarhed, udvidelsesmuligheder** og **vedligeholdelse**. MCP im√∏dekommer disse behov ved at:

- Samle model-v√¶rkt√∏jsintegrationer
- Reducere skr√∏belige, engangs-tilpassede l√∏sninger
- Muligg√∏re, at flere modeller kan eksistere i √©t √∏kosystem

---

## **üìö L√¶ringsm√•l**

N√•r du har l√¶st denne artikel, vil du kunne:

- Definere **Model Context Protocol (MCP)** og dets anvendelser
- Forst√• hvordan MCP standardiserer kommunikation mellem model og v√¶rkt√∏j
- Identificere de centrale komponenter i MCP-arkitekturen
- Udforske virkelige anvendelser af MCP i erhvervs- og udviklingssammenh√¶nge

---

## **üí° Hvorfor Model Context Protocol (MCP) er en game-changer**

### **üîó MCP l√∏ser fragmentering i AI-interaktioner**

F√∏r MCP kr√¶vede integration af modeller med v√¶rkt√∏jer:

- Tilpasset kode for hvert v√¶rkt√∏j-model-par
- Ikke-standardiserede API‚Äôer for hver leverand√∏r
- Hyppige fejl ved opdateringer
- D√•rlig skalerbarhed med flere v√¶rkt√∏jer

### **‚úÖ Fordele ved MCP-standardisering**

| **Fordel**               | **Beskrivelse**                                                                 |
|--------------------------|--------------------------------------------------------------------------------|
| Interoperabilitet        | LLM‚Äôer arbejder gnidningsfrit med v√¶rkt√∏jer fra forskellige leverand√∏rer       |
| Konsistens               | Ensartet adf√¶rd p√• tv√¶rs af platforme og v√¶rkt√∏jer                             |
| Genanvendelighed         | V√¶rkt√∏jer bygget √©n gang kan bruges p√• tv√¶rs af projekter og systemer          |
| Hurtigere udvikling      | Reducer udviklingstid ved at bruge standardiserede plug-and-play interfaces    |

---

## **üß± Overordnet MCP-arkitektur**

MCP f√∏lger en **client-server-model**, hvor:

- **MCP Hosts** k√∏rer AI-modellerne  
- **MCP Clients** initierer foresp√∏rgsler  
- **MCP Servers** leverer kontekst, v√¶rkt√∏jer og funktioner  

### **N√∏glekomponenter:**

- **Resources** ‚Äì Statisk eller dynamisk data til modeller  
- **Prompts** ‚Äì Foruddefinerede workflows til styret generering  
- **Tools** ‚Äì Eksekverbare funktioner som s√∏gning, beregninger  
- **Sampling** ‚Äì Agent-lignende adf√¶rd via rekursive interaktioner  

---

## Hvordan MCP-servers fungerer

MCP-servers fungerer p√• f√∏lgende m√•de:

- **Foresp√∏rgselsflow**:  
    1. MCP Client sender en foresp√∏rgsel til AI-modellen, der k√∏rer i en MCP Host.  
    2. AI-modellen identificerer, hvorn√•r den har brug for eksterne v√¶rkt√∏jer eller data.  
    3. Modellen kommunikerer med MCP Serveren via den standardiserede protokol.

- **MCP Server funktionalitet**:  
    - Tool Registry: Vedligeholder en katalog over tilg√¶ngelige v√¶rkt√∏jer og deres funktioner.  
    - Autentifikation: Bekr√¶fter tilladelser til adgang til v√¶rkt√∏jer.  
    - Request Handler: Behandler indkommende v√¶rkt√∏jsforesp√∏rgsler fra modellen.  
    - Response Formatter: Strukturerer v√¶rkt√∏jsoutput i et format, som modellen kan forst√•.

- **V√¶rkt√∏jseksekvering**:  
    - Serveren sender foresp√∏rgsler til de relevante eksterne v√¶rkt√∏jer  
    - V√¶rkt√∏jerne udf√∏rer deres specialiserede funktioner (s√∏gning, beregning, databaseforesp√∏rgsler osv.)  
    - Resultater returneres til modellen i et konsistent format.

- **Svarafslutning**:  
    - AI-modellen indarbejder v√¶rkt√∏jsoutput i sit svar.  
    - Det endelige svar sendes tilbage til klientapplikationen.

```mermaid
graph TD
    A[AI Model in MCP Host] <-->|MCP Protocol| B[MCP Server]
    B <-->|Tool Interface| C[Tool 1: Web Search]
    B <-->|Tool Interface| D[Tool 2: Calculator]
    B <-->|Tool Interface| E[Tool 3: Database Access]
    B <-->|Tool Interface| F[Tool 4: File System]
    
    Client[MCP Client/Application] -->|Sends Request| A
    A -->|Returns Response| Client
    
    subgraph "MCP Server Components"
        B
        G[Tool Registry]
        H[Authentication]
        I[Request Handler]
        J[Response Formatter]
    end
    
    B <--> G
    B <--> H
    B <--> I
    B <--> J
    
    style A fill:#f9d5e5,stroke:#333,stroke-width:2px
    style B fill:#eeeeee,stroke:#333,stroke-width:2px
    style Client fill:#d5e8f9,stroke:#333,stroke-width:2px
    style C fill:#c2f0c2,stroke:#333,stroke-width:1px
    style D fill:#c2f0c2,stroke:#333,stroke-width:1px
    style E fill:#c2f0c2,stroke:#333,stroke-width:1px
    style F fill:#c2f0c2,stroke:#333,stroke-width:1px    
```

## üë®‚Äçüíª S√•dan bygger du en MCP-server (med eksempler)

MCP-servers giver dig mulighed for at udvide LLM-funktionaliteter ved at levere data og funktionalitet.

Klar til at pr√∏ve? Her er eksempler p√•, hvordan man opretter en simpel MCP-server i forskellige sprog:

- **Python-eksempel**: https://github.com/modelcontextprotocol/python-sdk

- **TypeScript-eksempel**: https://github.com/modelcontextprotocol/typescript-sdk

- **Java-eksempel**: https://github.com/modelcontextprotocol/java-sdk

- **C#/.NET-eksempel**: https://github.com/modelcontextprotocol/csharp-sdk


## üåç Virkelige anvendelsestilf√¶lde for MCP

MCP muligg√∏r en bred vifte af applikationer ved at udvide AI‚Äôs muligheder:

| **Anvendelse**             | **Beskrivelse**                                                                |
|----------------------------|--------------------------------------------------------------------------------|
| Enterprise Data Integration | Forbind LLM‚Äôer til databaser, CRM-systemer eller interne v√¶rkt√∏jer            |
| Agentic AI Systems          | Muligg√∏r autonome agenter med adgang til v√¶rkt√∏jer og beslutningsworkflows    |
| Multi-modale applikationer  | Kombiner tekst-, billede- og lydv√¶rkt√∏jer i √©n samlet AI-app                  |
| Real-time Data Integration  | Integrer live data i AI-interaktioner for mere pr√¶cise og aktuelle resultater |

### üß† MCP = Universal standard for AI-interaktioner

Model Context Protocol (MCP) fungerer som en universel standard for AI-interaktioner, ligesom USB-C standardiserede fysiske forbindelser for enheder. I AI-verdenen leverer MCP et ensartet interface, der g√∏r det muligt for modeller (clients) at integrere gnidningsfrit med eksterne v√¶rkt√∏jer og dataleverand√∏rer (servers). Dette eliminerer behovet for mange forskellige, tilpassede protokoller for hver API eller datakilde.

Under MCP f√∏lger et MCP-kompatibelt v√¶rkt√∏j (kaldet en MCP-server) en f√¶lles standard. Disse servere kan liste de v√¶rkt√∏jer eller handlinger, de tilbyder, og udf√∏re disse handlinger, n√•r en AI-agent anmoder om det. AI-agentplatforme, der underst√∏tter MCP, kan opdage tilg√¶ngelige v√¶rkt√∏jer fra serverne og kalde dem gennem denne standardiserede protokol.

### üí° Muligg√∏r adgang til viden

Ud over at tilbyde v√¶rkt√∏jer muligg√∏r MCP ogs√• adgang til viden. Det g√∏r det muligt for applikationer at give kontekst til store sprogmodeller (LLMs) ved at forbinde dem til forskellige datakilder. For eksempel kan en MCP-server repr√¶sentere en virksomheds dokumentarkiv, s√• agenter kan hente relevant information efter behov. En anden server kan h√•ndtere specifikke handlinger som at sende e-mails eller opdatere poster. Fra agentens perspektiv er disse blot v√¶rkt√∏jer, den kan bruge ‚Äì nogle v√¶rkt√∏jer returnerer data (videns-kontekst), mens andre udf√∏rer handlinger. MCP h√•ndterer begge dele effektivt.

En agent, der forbinder til en MCP-server, l√¶rer automatisk serverens tilg√¶ngelige funktioner og tilg√¶ngelige data via et standardformat. Denne standardisering muligg√∏r dynamisk tilg√¶ngelighed af v√¶rkt√∏jer. For eksempel kan tilf√∏jelsen af en ny MCP-server til en agents system g√∏re dens funktioner straks brugbare uden yderligere tilpasning af agentens instruktioner.

Denne str√∏mlinede integration f√∏lger flowet vist i mermaid-diagrammet, hvor servere leverer b√•de v√¶rkt√∏jer og viden, hvilket sikrer gnidningsfrit samarbejde p√• tv√¶rs af systemer.

### üëâ Eksempel: Skalerbar agentl√∏sning

```mermaid
graph TD
    User -->|Prompt| LLM
    LLM -->|Response| User
    LLM -->|MCP| ServerA
    LLM -->|MCP| ServerB
    ServerA -->|Universal connector| ServerB
    ServerA --> KnowledgeA
    ServerA --> ToolsA
    ServerB --> KnowledgeB
    ServerB --> ToolsB

    subgraph Server A
        KnowledgeA[Knowledge]
        ToolsA[Tools]
    end

    subgraph Server B
        KnowledgeB[Knowledge]
        ToolsB[Tools]
    end
```

### üîÑ Avancerede MCP-scenarier med klient-side LLM-integration

Ud over den grundl√¶ggende MCP-arkitektur findes der avancerede scenarier, hvor b√•de klient og server indeholder LLM‚Äôer, hvilket muligg√∏r mere sofistikerede interaktioner:

```mermaid
sequenceDiagram
    autonumber
    actor User as üë§ User
    participant ClientApp as üñ•Ô∏è Client App
    participant ClientLLM as üß† Client LLM
    participant Server1 as üîß MCP Server 1
    participant Server2 as üìö MCP Server 2
    participant ServerLLM as ü§ñ Server LLM
    
    %% Discovery Phase
    rect rgb(220, 240, 255)
        Note over ClientApp, Server2: TOOL DISCOVERY PHASE
        ClientApp->>+Server1: Request available tools/resources
        Server1-->>-ClientApp: Return tool list (JSON)
        ClientApp->>+Server2: Request available tools/resources
        Server2-->>-ClientApp: Return tool list (JSON)
        Note right of ClientApp: Store combined tool<br/>catalog locally
    end
    
    %% User Interaction
    rect rgb(255, 240, 220)
        Note over User, ClientLLM: USER INTERACTION PHASE
        User->>+ClientApp: Enter natural language prompt
        ClientApp->>+ClientLLM: Forward prompt + tool catalog
        ClientLLM->>-ClientLLM: Analyze prompt & select tools
    end
    
    %% Scenario A: Direct Tool Calling
    alt Direct Tool Calling
        rect rgb(220, 255, 220)
            Note over ClientApp, Server1: SCENARIO A: DIRECT TOOL CALLING
            ClientLLM->>+ClientApp: Request tool execution
            ClientApp->>+Server1: Execute specific tool
            Server1-->>-ClientApp: Return results
            ClientApp->>+ClientLLM: Process results
            ClientLLM-->>-ClientApp: Generate response
            ClientApp-->>-User: Display final answer
        end
    
    %% Scenario B: Feature Negotiation (VS Code style)
    else Feature Negotiation (VS Code style)
        rect rgb(255, 220, 220)
            Note over ClientApp, ServerLLM: SCENARIO B: FEATURE NEGOTIATION
            ClientLLM->>+ClientApp: Identify needed capabilities
            ClientApp->>+Server2: Negotiate features/capabilities
            Server2->>+ServerLLM: Request additional context
            ServerLLM-->>-Server2: Provide context
            Server2-->>-ClientApp: Return available features
            ClientApp->>+Server2: Call negotiated tools
            Server2-->>-ClientApp: Return results
            ClientApp->>+ClientLLM: Process results
            ClientLLM-->>-ClientApp: Generate response
            ClientApp-->>-User: Display final answer
        end
    end
```

## üîê Praktiske fordele ved MCP

Her er de praktiske fordele ved at bruge MCP:

- **Aktualitet**: Modeller kan f√• adgang til opdateret information ud over deres tr√¶ningsdata  
- **Udvidelse af kapabiliteter**: Modeller kan bruge specialiserede v√¶rkt√∏jer til opgaver, de ikke er tr√¶net til  
- **Reduceret hallucination**: Eksterne datakilder giver faktuel forankring  
- **Privatliv**: F√∏lsomme data kan forblive i sikre milj√∏er i stedet for at v√¶re indlejret i prompts  

## üìå Vigtige pointer

Her er de vigtigste pointer om brugen af MCP:

- **MCP** standardiserer, hvordan AI-modeller interagerer med v√¶rkt√∏jer og data  
- Fremmer **udvidelsesmuligheder, konsistens og interoperabilitet**  
- MCP hj√¶lper med at **forkorte udviklingstid, forbedre p√•lidelighed og udvide modelkapaciteter**  
- Client-server-arkitekturen **muligg√∏r fleksible, udvidelige AI-applikationer**

## üß† √òvelse

T√¶nk p√• en AI-applikation, du gerne vil bygge.

- Hvilke **eksterne v√¶rkt√∏jer eller data** kunne forbedre dens kapaciteter?  
- Hvordan kan MCP g√∏re integrationen **nemmere og mere p√•lidelig?**

## Yderligere ressourcer

- [MCP GitHub Repository](https://github.com/modelcontextprotocol)


## Hvad nu?

N√¶ste: [Kapitel 1: Kernebegreber](/01-CoreConcepts/README.md)

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.