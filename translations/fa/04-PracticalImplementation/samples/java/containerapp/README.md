<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e5ea5e7582f70008ea9bec3b3820f20a",
  "translation_date": "2025-05-17T14:22:02+00:00",
  "source_file": "04-PracticalImplementation/samples/java/containerapp/README.md",
  "language_code": "fa"
}
-->
## معماری سیستم

این پروژه یک برنامه وب را نشان می‌دهد که قبل از ارسال درخواست‌های کاربر به سرویس ماشین‌حساب از پروتکل Model Context Protocol (MCP) برای بررسی ایمنی محتوا استفاده می‌کند.

### نحوه عملکرد

1. **ورودی کاربر**: کاربر یک درخواست محاسبه را در رابط وب وارد می‌کند
2. **بررسی ایمنی محتوا (ورودی)**: درخواست توسط API ایمنی محتوای Azure تحلیل می‌شود
3. **تصمیم‌گیری ایمنی (ورودی)**:
   - اگر محتوا امن باشد (شدت < 2 در همه دسته‌ها)، به ماشین‌حساب ارسال می‌شود
   - اگر محتوا به عنوان بالقوه مضر علامت‌گذاری شود، فرآیند متوقف شده و هشدار برگردانده می‌شود
4. **ادغام ماشین‌حساب**: محتوای امن توسط LangChain4j پردازش می‌شود که با سرور ماشین‌حساب MCP ارتباط برقرار می‌کند
5. **بررسی ایمنی محتوا (خروجی)**: پاسخ ربات توسط API ایمنی محتوای Azure تحلیل می‌شود
6. **تصمیم‌گیری ایمنی (خروجی)**:
   - اگر پاسخ ربات امن باشد، به کاربر نمایش داده می‌شود
   - اگر پاسخ ربات به عنوان بالقوه مضر علامت‌گذاری شود، با هشدار جایگزین می‌شود
7. **پاسخ**: نتایج (اگر امن باشند) همراه با هر دو تحلیل ایمنی به کاربر نمایش داده می‌شود

## استفاده از پروتکل Model Context Protocol (MCP) با خدمات ماشین‌حساب

این پروژه نشان می‌دهد که چگونه از پروتکل Model Context Protocol (MCP) برای فراخوانی خدمات ماشین‌حساب MCP از LangChain4j استفاده کنید. پیاده‌سازی از یک سرور MCP محلی که روی پورت 8080 اجرا می‌شود برای ارائه عملیات ماشین‌حساب استفاده می‌کند.

### تنظیم سرویس ایمنی محتوای Azure

قبل از استفاده از ویژگی‌های ایمنی محتوا، نیاز دارید که یک منبع سرویس ایمنی محتوای Azure ایجاد کنید:

1. وارد [پرتال Azure](https://portal.azure.com) شوید
2. روی "ایجاد منبع" کلیک کنید و "ایمنی محتوا" را جستجو کنید
3. "ایمنی محتوا" را انتخاب کرده و روی "ایجاد" کلیک کنید
4. یک نام منحصر به فرد برای منبع خود وارد کنید
5. اشتراک و گروه منابع خود را انتخاب کنید (یا یک گروه جدید ایجاد کنید)
6. یک منطقه پشتیبانی شده را انتخاب کنید (برای جزئیات، [دسترسی منطقه‌ای](https://azure.microsoft.com/en-us/global-infrastructure/services/?products=cognitive-services) را بررسی کنید)
7. یک سطح قیمت‌گذاری مناسب را انتخاب کنید
8. روی "ایجاد" کلیک کنید تا منبع مستقر شود
9. پس از اتمام استقرار، روی "رفتن به منبع" کلیک کنید
10. در پنل سمت چپ، زیر "مدیریت منابع"، "کلیدها و نقطه پایانی" را انتخاب کنید
11. یکی از کلیدها و URL نقطه پایانی را برای استفاده در مرحله بعد کپی کنید

### پیکربندی متغیرهای محیطی

متغیر محیطی `GITHUB_TOKEN` را برای احراز هویت مدل‌های GitHub تنظیم کنید:
```sh
export GITHUB_TOKEN=<your_github_token>
```

برای ویژگی‌های ایمنی محتوا، تنظیم کنید:
```sh
export CONTENT_SAFETY_ENDPOINT=<your_content_safety_endpoint>
export CONTENT_SAFETY_KEY=<your_content_safety_key>
```

این متغیرهای محیطی توسط برنامه برای احراز هویت با سرویس ایمنی محتوای Azure استفاده می‌شوند. اگر این متغیرها تنظیم نشوند، برنامه از مقادیر جایگزین برای اهداف نمایشی استفاده می‌کند، اما ویژگی‌های ایمنی محتوا به درستی کار نخواهند کرد.

### راه‌اندازی سرور ماشین‌حساب MCP

قبل از اجرای کلاینت، نیاز دارید که سرور ماشین‌حساب MCP را در حالت SSE روی localhost:8080 راه‌اندازی کنید.

## توضیحات پروژه

این پروژه ادغام پروتکل Model Context Protocol (MCP) با LangChain4j را برای فراخوانی خدمات ماشین‌حساب نشان می‌دهد. ویژگی‌های کلیدی شامل:

- استفاده از MCP برای اتصال به سرویس ماشین‌حساب برای عملیات ریاضی پایه
- بررسی ایمنی محتوا در دو لایه روی درخواست‌های کاربر و پاسخ‌های ربات
- ادغام با مدل gpt-4.1-nano GitHub از طریق LangChain4j
- استفاده از رویدادهای ارسال شده توسط سرور (SSE) برای انتقال MCP

## ادغام ایمنی محتوا

پروژه شامل ویژگی‌های جامع ایمنی محتوا است تا اطمینان حاصل شود که هم ورودی‌های کاربر و هم پاسخ‌های سیستم از محتوای مضر عاری هستند:

1. **بررسی ورودی**: همه درخواست‌های کاربر برای دسته‌های محتوای مضر مانند سخنان نفرت‌انگیز، خشونت، خودآزاری و محتوای جنسی قبل از پردازش تحلیل می‌شوند.

2. **بررسی خروجی**: حتی هنگام استفاده از مدل‌های بالقوه بدون سانسور، سیستم همه پاسخ‌های تولید شده را از طریق همان فیلترهای ایمنی محتوا بررسی می‌کند قبل از نمایش به کاربر.

این رویکرد دو لایه تضمین می‌کند که سیستم بدون توجه به اینکه از کدام مدل AI استفاده می‌شود، ایمن باقی می‌ماند و کاربران را از ورودی‌های مضر و خروجی‌های بالقوه مشکل‌ساز تولید شده توسط AI محافظت می‌کند.

## کلاینت وب

برنامه شامل یک رابط وب کاربرپسند است که به کاربران اجازه می‌دهد با سیستم ماشین‌حساب ایمنی محتوا تعامل داشته باشند:

### ویژگی‌های رابط وب

- فرم ساده و شهودی برای وارد کردن درخواست‌های محاسبه
- اعتبارسنجی ایمنی محتوا در دو لایه (ورودی و خروجی)
- بازخورد در زمان واقعی درباره ایمنی درخواست و پاسخ
- شاخص‌های ایمنی رنگی برای تفسیر آسان
- طراحی تمیز و پاسخگو که روی دستگاه‌های مختلف کار می‌کند
- مثال‌های درخواست امن برای راهنمایی کاربران

### استفاده از کلاینت وب

1. برنامه را شروع کنید:
   ```sh
   mvn spring-boot:run
   ```

2. مرورگر خود را باز کنید و به `http://localhost:8087` بروید

3. یک درخواست محاسبه را در ناحیه متن ارائه شده وارد کنید (مثلاً "مجموع 24.5 و 17.3 را محاسبه کنید")

4. روی "ارسال" کلیک کنید تا درخواست شما پردازش شود

5. نتایج را مشاهده کنید که شامل خواهد شد:
   - تحلیل ایمنی محتوای درخواست شما
   - نتیجه محاسبه (اگر درخواست امن بود)
   - تحلیل ایمنی محتوای پاسخ ربات
   - هرگونه هشدار ایمنی اگر ورودی یا خروجی علامت‌گذاری شده باشد

کلاینت وب به طور خودکار هر دو فرآیند اعتبارسنجی ایمنی محتوا را مدیریت می‌کند و اطمینان حاصل می‌کند که همه تعاملات ایمن و مناسب هستند بدون توجه به اینکه از کدام مدل AI استفاده می‌شود.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌ها باشند. سند اصلی به زبان مادری باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیتی در قبال هرگونه سوء تفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.